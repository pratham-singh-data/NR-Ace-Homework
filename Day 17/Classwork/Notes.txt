Types of asymptotic notations:
1) Big Oh Notation (Mainly used for worst case)
2) Big Theta Notation (Mainly used for avergae case)
3) Big Omega Notation (Mainly used for best case)

Consider the linear search algorithm:
    Here you are given a target and an array and you traverse the array till target is found then return 
    index of location.

    int flag = -1;
    for(int i = 0; i < n; i++){
        if(arr[i] == x){
            cout << "target is present";
            flag = 1;
            break;
        }
    }

    if(flag == -1){
        cout << "X is absent";
    }

Best Case: First accessed element is the target. We consider time taken for this possibility.
Worst Case: Element is absent or present at the end. We consider time taken for these possibilities.

Averate Case: This needs to be calculated.
    for each index; it required index traversals to reach so:
    avergae case = sum of all indices / n;

In General:
    Average case complexity = (sum of time taken by each possibility) / (total possibilities)  


In General:
Big-Oh (lower bound):
    f(x) = c g(x)
        where c is a constant
    
    f(x) = O(g(x))
    if for all values of x;
    g(x) >= f(x)

    which means that the grphical plot of all c g(x) (for any value of c) will lie below the plot of f(x).
    eg: consider pow(n, 2) and n
        if we plot these two, there is no possible value where value of n is greater than pow(n, 2)

    Now again if we consider n and nlog n we will notice that initially nlogn lies below n, but after a 
    certain point n falls below nlogn (after base - 1) hence we prefer nlogn over n when writing big oh 
    complexity.

Q: f(n) = n
    g(n) = pow(n, 2)
    h(n) = pow(n, 3)
    k(n) = n*log(n)
    l(n) = n!
    m(n) = log(n)

1) is m(n) = O(g(n)) correct?
=> m(n) = log(n)
    g(n) = pow(n, 2)
    true; log(n) plot lies below pow(n, 2)

2) k(n) = O(h(n))
=> k(n) = n*log(n)
    h(n) = pow(n, 3)
    true

3) l(n) = O(g(n))
=> l(n) = n!
    g(n) = pow(n, 2)
    false; n! increases rapidly and pow(n, 2) is below n! after a point


4) k(n) = O(m(n))
=> k(n) = n*log(n)
    m(n) = log(n)
    false; plot of n*log(n) is above log(n)

Notice that a single function many have many big-oh functions, but we only want one, which should we 
choose, for this we use tightest upper bound. This is the one that gives the least error eg:
1) for pow(n, 2) and;
    O(pow(n, 2))
    O(pow(2, n))
    O(pow(n, 3))
    O(pow(n, 4))
    O(n!)
=> Tightest upper bound is O(pow(n, 2))
    Second tightest upper bound is O(pow(n, 3)).

Now we need the opposite oof this, that's the big-omega notation (lower bound)
    f(x) = c g(x)
        where c is a constant
    
    f(x) = Omega(g(x))
    if for all values of x;
    g(x) <= f(x)

Q) Which of the following is pow(n, 2)
    Omega(1)
    Omega(log(n))
    Omega(n!)
    Omega(n * log(n))
=> Omega(1)
    Omega(log(n))
    Omega(n*log(n))

=> Tightest lower bound: O(pow(n, 2))

Now;
    f(x) = Theta(g(x))
    iff f(x) = O(g(x)) && f(x) = Omega(g(x))

Q) f(x) = pow(n, 2) + 5n + 8
    g(x) = n * log(n) + 8 * pow(n, 2) + 9n
    if f(x) = Thetha(g(x))
=> f(x) = pow(n, 2)
    g(x) = pow(n, 2)
    true

Q) f(x) = 5 * pow(2, n) + pow(n, 2) + n!
    g(x) = 100000 * n! + pow(n, 3) + 8 * n!
1) f(x) = O(g(x))
=> f(x) = n!
    g(x) = n!
    true

2) f(x) = Thetha(g(x))
=> f(x) = n!
    g(x) = n!
    true

Q) f(x) = 5 * pow(n, n) + pow(n, 2) + n!
    g(x) = 100000 * n! + pow(n, 3) + 8 * n!
1) f(x) = O(g(x))
=> f(x) = pow(n, n)
    g(x) = n!
    false

2) f(x) = Thetha(g(x))
=> f(x) = pow(n, n)
    g(x) = n!
    false

Q) Order the following:
    a) pow(n, 3)
    b) n!
    c) 1
    d) n * log(n)
    e) n
    f) log(n)
    g) pow(n, 1/2)
    h) pow(n, 1/3)
    i) n * pow(log(n), 2)
    j) pow(n, 2)
    k) pow(n, n)
=> k > b > a > j > i > d > e > g > h > f > c

Q) Tell all case time complexity of sum of elements of an array:
=> O(n), Omega(n), Thetha(n)
    as we have to traverse fulll array no matter what.

Q)
    for(int i = 0; i < log(n, 2); i += 5){
        int k = i;
        for(int j = 1; j < n; j *= 2){
            fun2(j);
        }
    }

    fun2(int x){
        for(int i = 0; i < x; i++){
            if(i == x)
                break;
        }
    }
=>
    Best case: Termination at first iteration; Omega(1)
    Worst Case:
        outer loop: log(n, 2)/5
        inner loop: log(n, 2)
        fun2(): GP
        break statement never runs
        
        So;
            n * log(n)

Q) 
    for(int i = 0; i < n; i++){
        for(int j = 0; j < i; j++){
            cout << "Hello";
        }
    }
=>  inner: AP of 1 to outer:
            (x * (x - 1)) / 2
    outer: n
    Answer: n + (n * (n - 1)/ 2)
            pow(n, 2)

Sum of GP to n terms:
    sum = a *(pow(r, n) - 1) / (r - 1)

Q)
    for(int i = 0; i < log(n, 2); i += 5){
        int k = i;
        for(int j = 1; j < i; j *= 2){
            fun2(j);
        }
    }

    fun2(int x){
        for(int i = 0; i < x; i++){
            if(i == x)
                break;
        }
    }
=>
    fun2: O(x)
    inner: dependedent on outer
        i => runs
        0 => 0

        5 => j => fun2 runs
            1 => 1
            2 => 2
            4 => 4
        
        10 => j => fun2 runs
            1 => 1
            2 => 2
            4 => 4
            8 => 8
        
        15 => j => fun2 runs
            1 => 1
            2 => 2
            4 => 4
            8 => 8

        Say total iterations is m:
            1 occurs m times, 
            2 occurs m times,
            4 occurs m times,
            8 occurs m - 2 times,
            16 occurs m - 2 times, and so on...
        1*m + 2*m + 3*m + 4*(m - 1) + ... + m*(1 + 2 + ... + log(n, 2))
        This evaluates to pow(2, log(log(n, 2), 2))

    outer: log(n, 2) / 5

    final = pow(log(n, 2), 2)